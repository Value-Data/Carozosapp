# ğŸ” INFORME DE ERROR - Durazno Blanco

## âŒ Error Encontrado

```
ValueError: Bin labels must be one fewer than the number of bin edges
```

## ğŸ“Š AnÃ¡lisis del Problema

### Contexto
El error ocurre al procesar **Durazno Blanco** cuando se intenta crear clusters con `K >= 3`.

### Causa RaÃ­z

**Durazno Blanco tiene caracterÃ­sticas especiales:**

1. **Cantidad de datos limitada:**
   - Total de mercados-clientes: **7**
   - Valores Ãºnicos de KILOS_ASIGNABLE: **4**
   - Valores repetidos: **4 mercados tienen exactamente el mismo valor** (45,851.24)

2. **DistribuciÃ³n de valores:**
   ```
   Valor          | Frecuencia
   -------------- | ----------
   5,310.83       | 1 vez
   40,660.56      | 1 vez
   45,851.24      | 4 veces (57% de los datos)
   53,139.87      | 1 vez
   ```

3. **Problema tÃ©cnico:**
   - `pd.qcut()` intenta crear `K` bins basÃ¡ndose en cuantiles
   - Cuando `K > valores_Ãºnicos`, `pd.qcut()` puede crear **menos bins** de los solicitados debido a valores duplicados
   - Sin embargo, se le pasan `K` labels (`range(1, K+1)`)
   - **Resultado**: MÃ¡s labels que bins disponibles â†’ Error

### CuÃ¡ndo Ocurre

El error se produce cuando:
- `K >= valores_Ãºnicos` (en este caso, `K >= 4`)
- Hay valores duplicados en la serie
- `pd.qcut()` crea menos bins de los solicitados por `duplicates="drop"`

### Ejemplo del Flujo

```python
# Durazno Blanco: 7 valores, 4 Ãºnicos
K = 5  # Se solicitan 5 clusters

# pd.qcut intenta crear 5 bins
# Pero solo hay 4 valores Ãºnicos
# duplicates="drop" elimina bins vacÃ­os
# Resultado: Solo se crean 4 bins

# Pero se le pasan 5 labels: range(1, 6) = [1, 2, 3, 4, 5]
# 4 bins vs 5 labels â†’ ValueError
```

## ğŸ”§ SoluciÃ³n Propuesta

### OpciÃ³n 1: Ajustar dinÃ¡micamente K (Recomendada)
Ajustar automÃ¡ticamente `K` para que no sea mayor que el nÃºmero de valores Ãºnicos:

```python
def assign_clusters_quantiles(series: pd.Series, k: int):
    s = pd.to_numeric(series, errors="coerce").fillna(0.0)
    if s.nunique() <= 1:
        return pd.Series(np.ones(len(s), dtype=int), index=s.index)
    
    # Ajustar K al nÃºmero de valores Ãºnicos
    k_ajustado = min(k, s.nunique())
    
    try:
        labels = pd.qcut(
            s.rank(method="average", ascending=True),
            q=k_ajustado,
            labels=range(1, k_ajustado+1),
            duplicates="drop"
        ).astype(int)
    except ValueError:
        # Si aÃºn falla, usar bins uniformes
        bins = np.linspace(s.min(), s.max(), num=k_ajustado+1)
        labels = pd.cut(s, bins=bins, labels=range(1, k_ajustado+1), include_lowest=True).astype(int)
    
    # Si se pidieron mÃ¡s clusters de los posibles, rellenar
    if labels.nunique() < k_ajustado:
        bins = np.linspace(s.min(), s.max(), num=k_ajustado+1)
        labels = pd.cut(s, bins=bins, labels=range(1, k_ajustado+1), include_lowest=True).astype(int)
    
    return labels
```

### OpciÃ³n 2: Usar pd.cut() directamente
Cuando hay valores duplicados, usar divisiÃ³n uniforme en lugar de cuantiles:

```python
def assign_clusters_quantiles(series: pd.Series, k: int):
    s = pd.to_numeric(series, errors="coerce").fillna(0.0)
    if s.nunique() <= 1:
        return pd.Series(np.ones(len(s), dtype=int), index=s.index)
    
    k_ajustado = min(k, s.nunique())
    
    # Si hay valores duplicados significativos, usar cut
    if s.nunique() < len(s) * 0.5:  # MÃ¡s del 50% duplicados
        bins = np.linspace(s.min(), s.max(), num=k_ajustado+1)
        return pd.cut(s, bins=bins, labels=range(1, k_ajustado+1), include_lowest=True).astype(int)
    
    # Caso normal: usar qcut
    try:
        labels = pd.qcut(
            s.rank(method="average", ascending=True),
            q=k_ajustado,
            labels=range(1, k_ajustado+1),
            duplicates="drop"
        ).astype(int)
        
        if labels.nunique() < k_ajustado:
            bins = np.linspace(s.min(), s.max(), num=k_ajustado+1)
            labels = pd.cut(s, bins=bins, labels=range(1, k_ajustado+1), include_lowest=True).astype(int)
        
        return labels
    except ValueError:
        bins = np.linspace(s.min(), s.max(), num=k_ajustado+1)
        return pd.cut(s, bins=bins, labels=range(1, k_ajustado+1), include_lowest=True).astype(int)
```

### OpciÃ³n 3: ValidaciÃ³n en la UI (Preventiva)
Advertir al usuario cuando `K > mercados_clientes`:

```python
# En app.py
if k > len(resumen_mc):
    st.warning(f"âš ï¸ Advertencia: El nÃºmero de clusters ({k}) es mayor que el nÃºmero de mercados-clientes ({len(resumen_mc)}). Se ajustarÃ¡ automÃ¡ticamente.")
    k = min(k, len(resumen_mc))
```

## ğŸ“ˆ ComparaciÃ³n de Casos

| Especie | Mercados-Clientes | Valores Ãšnicos | K MÃ¡ximo Viable | Estado |
|---------|-------------------|----------------|-----------------|--------|
| Nectarin Amarillo | 32 | 32 | 32 | âœ… OK |
| Durazno Blanco | 7 | 4 | 4 | âŒ Error con K>=3 |

## âœ… RecomendaciÃ³n Final

**Implementar OpciÃ³n 1 con OpciÃ³n 3:**
1. Ajustar automÃ¡ticamente `K` en la funciÃ³n de clustering
2. Advertir al usuario en la UI si se solicitan mÃ¡s clusters de los posibles
3. Mostrar informaciÃ³n sobre cuÃ¡ntos clusters realmente se crearon

Esto garantiza:
- âœ… Compatibilidad con todos los casos (muchos o pocos datos)
- âœ… Experiencia de usuario clara
- âœ… Sin errores inesperados
- âœ… Resultados consistentes

## ğŸ§ª Pruebas Recomendadas

1. âœ… Durazno Blanco (caso con pocos datos)
2. âœ… Nectarin Amarillo (caso normal)
3. âœ… Caso extremo: 3 mercados-clientes, K=5
4. âœ… Caso extremo: Todos los valores iguales

## ğŸ“ Notas Adicionales

- Este problema es comÃºn cuando hay **datos desbalanceados** o **muestras pequeÃ±as**
- La soluciÃ³n debe ser **robusta** y manejar todos los casos edge
- Es importante **informar al usuario** cuando se hace un ajuste automÃ¡tico

